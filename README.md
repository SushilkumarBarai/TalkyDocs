# ğŸ“˜ TalkyDocs: Smart PDF QnA System (RAG-powered)

TalkyDocs is a Streamlit-based Question & Answer system that enables users to upload any PDF document and instantly get accurate answers by asking natural language questions. Powered by Retrieval-Augmented Generation (RAG), Ollama LLMs, ChromaDB vector search, and reranking with Sentence Transformers, TalkyDocs delivers high-quality, context-aware responses in real time.

---

## ğŸš€ Features

- ğŸ“„ Upload and process PDF documents
- ğŸ” Document chunking and vector storage using ChromaDB
- ğŸ§  Embedding powered by Ollamaâ€™s `nomic-embed-text` model
- âš™ï¸ Cosine similarity search for semantic relevance
- ğŸ“š Cross-encoder re-ranking using MS MARCO MiniLM
- ğŸ§¾ Context-aware LLM responses via `llama3.2:3b`
- ğŸ“¡ Real-time streaming of model responses
- ğŸ–¼ï¸ Simple, beautiful, and interactive Streamlit interface

---

## ğŸ¯ Use Cases

- ğŸ’° **Finance**: Ask questions over financial reports, regulatory filings, and investment summaries.
- âš–ï¸ **Legal**: Instantly extract insights from contracts, case laws, and legal policies.
- ğŸ¥ **Healthcare**: Query clinical papers, patient records, or drug research efficiently.
- ğŸ“ **Academia**: Summarize research papers and get answers from academic PDFs.
- ğŸ§‘â€ğŸ’¼ **HR & Training**: Retrieve information from policy documents and onboarding materials.

--

## ğŸ› ï¸ Tech Stack

- **Streamlit** â€“ UI framework.
- **ChromaDB** â€“ Persistent vector store.
- **Ollama** â€“ Local LLM server for inference & embedding.
- **LangChain** â€“ Document loading and splitting.
- **Sentence Transformers** â€“ Cross-encoder for reranking.
- **PyMuPDF** â€“ PDF parsing and reading.

---

## Screenshot 

Hereâ€™s a screenshot of the application:

### Sample 1


![Screenshot_1](https://github.com/SushilkumarBarai/TalkyDocs/blob/main/images/Screenshot_1.png)


### Sample 2

![Screenshot_2](https://github.com/SushilkumarBarai/TalkyDocs/blob/main/images/Screenshot_1.png)


### Sample 3

![Screenshot_2](https://github.com/SushilkumarBarai/TalkyDocs/blob/main/images/Screenshot_3.png)



## ğŸ“¦ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/SushilkumarBarai/TalkyDocs.git
cd TalkyDocs
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Start Ollama and Pull Required Models

```bash
ollama run nomic-embed-text
ollama run llama3.2:3b
```

### 4. Launch TalkyDocs

```bash
streamlit run app.py
```

